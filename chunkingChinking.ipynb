{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jJDl3rNwsMs"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aim: 3(a) Write a Python NLTK program to perform Chunking and Chinking on\n",
        "state_union corpus."
      ],
      "metadata": {
        "id": "NUI5I6d9wzSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import state_union\n",
        "from nltk.chunk import RegexpParser\n",
        "with state_union.open('1945-Truman.txt') as f:\n",
        "  data = f.read()\n",
        "  data = data.split(\"\\n\")[6]\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vy3kaLPwuIh",
        "outputId": "aea7280c-987b-44d2-a0fb-cdb88771de42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt. At a time like this, words are inadequate. The most eloquent tribute would be a reverent silence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "tokenizedText = word_tokenize(data)\n",
        "data = tokenizedText\n",
        "tags = nltk.pos_tag(data)\n",
        "tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFXLKICcxMKM",
        "outputId": "c6f4daa8-31f0-4da0-ce2b-cf3f72d551a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Only', 'RB'),\n",
              " ('yesterday', 'NN'),\n",
              " (',', ','),\n",
              " ('we', 'PRP'),\n",
              " ('laid', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('rest', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('mortal', 'NN'),\n",
              " ('remains', 'VBZ'),\n",
              " ('of', 'IN'),\n",
              " ('our', 'PRP$'),\n",
              " ('beloved', 'JJ'),\n",
              " ('President', 'NNP'),\n",
              " (',', ','),\n",
              " ('Franklin', 'NNP'),\n",
              " ('Delano', 'NNP'),\n",
              " ('Roosevelt', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('At', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('time', 'NN'),\n",
              " ('like', 'IN'),\n",
              " ('this', 'DT'),\n",
              " (',', ','),\n",
              " ('words', 'NNS'),\n",
              " ('are', 'VBP'),\n",
              " ('inadequate', 'JJ'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('most', 'RBS'),\n",
              " ('eloquent', 'JJ'),\n",
              " ('tribute', 'NN'),\n",
              " ('would', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('reverent', 'JJ'),\n",
              " ('silence', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking\n",
        "\n",
        "a chunk will be constructed when an optional Determiner (DT) is\n",
        "followed by any number of Adjective (JJ) or Noun (NN)"
      ],
      "metadata": {
        "id": "lMNEvU0OyAJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "result = cp.parse(tags)\n",
        "#result.draw()"
      ],
      "metadata": {
        "id": "iOiC4NGnxvxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChunkedCorpusReader\n"
      ],
      "metadata": {
        "id": "ySm4Xjf6yUaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "with open('temp.txt', 'w') as f:\n",
        "    f.write(nltk.corpus.state_union.raw('1945-Truman.txt')[:1000])\n",
        "\n",
        "with open('temp.txt', 'r') as f:\n",
        "    data = f.read()\n",
        "tokenizedText = word_tokenize(data)\n",
        "data = tokenizedText\n",
        "tags = nltk.pos_tag(data)"
      ],
      "metadata": {
        "id": "3bNvT7i0yHJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader import ChunkedCorpusReader\n",
        "x = ChunkedCorpusReader('.', 'temp.txt')\n",
        "tagged_sent = x.chunked_sents()\n",
        "print (\"Chunked Sentence : \\n\", tagged_sent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY9d_CecydwL",
        "outputId": "3f15539f-db49-4919-eced-b30fe56b1363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunked Sentence : \n",
            " [Tree('S', [('PRESIDENT', None), ('HARRY', None), ('S.', None), (\"TRUMAN'S\", None), ('ADDRESS', None), ('BEFORE', None), ('A', None), ('JOINT', None), ('SESSION', None), ('OF', None), ('THE', None), ('CONGRESS', None)]), Tree('S', [('April', None), ('16,', None), ('1945', None)]), ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp  =nltk.RegexpParser(grammar)\n",
        "result = cp.parse(tags)\n",
        "#result.draw()"
      ],
      "metadata": {
        "id": "kT1pMWLZyg2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chinking\n",
        "\n",
        "Chinking is a lot like chunking, it is basically a way for you to remove\n",
        "a chunk from a chunk. The chunk that you remove from your chunk is your\n",
        "chink."
      ],
      "metadata": {
        "id": "GS_ZuuwRynUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import state_union\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
        "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
        "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
        "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
        "def process_content():\n",
        "    try:\n",
        "        for i in tokenized[5:]:\n",
        "            words = nltk.word_tokenize(i)\n",
        "            tagged = nltk.pos_tag(words)\n",
        "            chunkGram = r\"\"\"Chunk: {<NN>|<JJ>}\n",
        "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
        "            chunkParser = nltk.RegexpParser(chunkGram)\n",
        "            chunked = chunkParser.parse(tagged)\n",
        "            chunked.draw()\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WY1tVlfylO2",
        "outputId": "5feedd76-8d35-4d49-9bb0-20747e05e4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no display name and no $DISPLAY environment variable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aim 3(b) Evaluate the test.txt data from conll2000 corpus after\n",
        "chunking(accuracy,precision,recall,f-measure)."
      ],
      "metadata": {
        "id": "5Angfysqy49a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('conll2000')\n",
        "from nltk.corpus import conll2000"
      ],
      "metadata": {
        "id": "w61bQyDGyzOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data= conll2000.chunked_sents()\n",
        "train_data=data[:10900]\n",
        "test_data=data[10900:]\n",
        "print(len(train_data),len(test_data))\n",
        "print(train_data[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcCYXd7ay8uA",
        "outputId": "92cf4fdf-20fb-4562-8104-67a09a867428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10900 48\n",
            "(S\n",
            "  Chancellor/NNP\n",
            "  (PP of/IN)\n",
            "  (NP the/DT Exchequer/NNP)\n",
            "  (NP Nigel/NNP Lawson/NNP)\n",
            "  (NP 's/POS restated/VBN commitment/NN)\n",
            "  (PP to/TO)\n",
            "  (NP a/DT firm/NN monetary/JJ policy/NN)\n",
            "  (VP has/VBZ helped/VBN to/TO prevent/VB)\n",
            "  (NP a/DT freefall/NN)\n",
            "  (PP in/IN)\n",
            "  (NP sterling/NN)\n",
            "  (PP over/IN)\n",
            "  (NP the/DT past/JJ week/NN)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wtc=tree2conlltags(train_data[1])\n",
        "wtc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH1Jeewu0aC9",
        "outputId": "c431c894-d02e-4668-a937-02cb3d4bb709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Chancellor', 'NNP', 'O'),\n",
              " ('of', 'IN', 'B-PP'),\n",
              " ('the', 'DT', 'B-NP'),\n",
              " ('Exchequer', 'NNP', 'I-NP'),\n",
              " ('Nigel', 'NNP', 'B-NP'),\n",
              " ('Lawson', 'NNP', 'I-NP'),\n",
              " (\"'s\", 'POS', 'B-NP'),\n",
              " ('restated', 'VBN', 'I-NP'),\n",
              " ('commitment', 'NN', 'I-NP'),\n",
              " ('to', 'TO', 'B-PP'),\n",
              " ('a', 'DT', 'B-NP'),\n",
              " ('firm', 'NN', 'I-NP'),\n",
              " ('monetary', 'JJ', 'I-NP'),\n",
              " ('policy', 'NN', 'I-NP'),\n",
              " ('has', 'VBZ', 'B-VP'),\n",
              " ('helped', 'VBN', 'I-VP'),\n",
              " ('to', 'TO', 'I-VP'),\n",
              " ('prevent', 'VB', 'I-VP'),\n",
              " ('a', 'DT', 'B-NP'),\n",
              " ('freefall', 'NN', 'I-NP'),\n",
              " ('in', 'IN', 'B-PP'),\n",
              " ('sterling', 'NN', 'B-NP'),\n",
              " ('over', 'IN', 'B-PP'),\n",
              " ('the', 'DT', 'B-NP'),\n",
              " ('past', 'JJ', 'I-NP'),\n",
              " ('week', 'NN', 'I-NP'),\n",
              " ('.', '.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree=conlltags2tree(wtc)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLjUfwhz0b6D",
        "outputId": "8a13ddc5-d8de-412e-930d-449243cc14b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  Chancellor/NNP\n",
            "  (PP of/IN)\n",
            "  (NP the/DT Exchequer/NNP)\n",
            "  (NP Nigel/NNP Lawson/NNP)\n",
            "  (NP 's/POS restated/VBN commitment/NN)\n",
            "  (PP to/TO)\n",
            "  (NP a/DT firm/NN monetary/JJ policy/NN)\n",
            "  (VP has/VBZ helped/VBN to/TO prevent/VB)\n",
            "  (NP a/DT freefall/NN)\n",
            "  (PP in/IN)\n",
            "  (NP sterling/NN)\n",
            "  (PP over/IN)\n",
            "  (NP the/DT past/JJ week/NN)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conll_tag_chunks(chunk_sents):\n",
        "    tagged_sents = [tree2conlltags(tree) for tree in chunk_sents]\n",
        "    return [[(t, c) for (w, t, c) in sent] for sent in tagged_sents]\n",
        "def combined_tagger(train_data, taggers, backoff=None):\n",
        "    for tagger in taggers:\n",
        "        backoff = tagger(train_data, backoff=backoff)\n",
        "    return backoff"
      ],
      "metadata": {
        "id": "flUabhWcy_YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import UnigramTagger, BigramTagger\n",
        "from nltk.chunk import ChunkParserI\n",
        "from nltk.chunk.util import tree2conlltags,conlltags2tree\n",
        "\n",
        "#Define the chunker class\n",
        "class NGramTagChunker(ChunkParserI):\n",
        "  def __init__(self,train_sentences,tagger_classes=[UnigramTagger,BigramTagger]):\n",
        "    train_sent_tags=conll_tag_chunks(train_sentences)\n",
        "    self.chunk_tagger=combined_tagger(train_sent_tags,tagger_classes)\n",
        "def parse(self,tagged_sentence):\n",
        "    if not tagged_sentence:\n",
        "      return None\n",
        "    pos_tags=[tag for word, tag in tagged_sentence]\n",
        "    chunk_pos_tags=self.chunk_tagger.tag(pos_tags)\n",
        "    chunk_tags=[chunk_tag for (pos_tag,chunk_tag) in chunk_pos_tags]\n",
        "    wpc_tags=[(word,pos_tag,chunk_tag) for ((word,pos_tag),chunk_tag) in zip(tagged_sentence,chunk_tags)]\n",
        "    return conlltags2tree(wpc_tags)\n",
        "#train chunker model\n",
        "ntc=NGramTagChunker(train_data)\n",
        "#evaluate chunker model performance\n",
        "print(ntc.evaluate(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "oOtKdJ2xzJ6b",
        "outputId": "09cc60db-bf35-4166-9191-12bafa58ea4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-b045e7ee9524>:21: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(ntc.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-b045e7ee9524>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mntc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNGramTagChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#evaluate chunker model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/internals.py\u001b[0m in \u001b[0;36mnewFunc\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mnewFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Copy the old function's name, docstring, & dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/chunk/api.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, gold)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use accuracy(gold) instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/chunk/api.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, gold)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mchunkscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChunkScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mchunkscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchunkscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/chunk/api.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use accuracy(gold) instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "sentence='Pluto goes for a walk with Aashi in the evening.'\n",
        "nltk_pos_tagged=nltk.pos_tag(sentence.split())\n",
        "pd.DataFrame(nltk_pos_tagged,columns=['word','POS tag'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ucAes-Dq1CqC",
        "outputId": "3576f5be-d90b-411c-ef5b-abf1362ed43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       word POS tag\n",
              "0     Pluto      NN\n",
              "1      goes     VBZ\n",
              "2       for      IN\n",
              "3         a      DT\n",
              "4      walk      NN\n",
              "5      with      IN\n",
              "6     Aashi     NNP\n",
              "7        in      IN\n",
              "8       the      DT\n",
              "9  evening.      NN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42c982e7-d4e2-44e9-855f-861e7c08ae18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>POS tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pluto</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>goes</td>\n",
              "      <td>VBZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>for</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>walk</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>with</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Aashi</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>evening.</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42c982e7-d4e2-44e9-855f-861e7c08ae18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42c982e7-d4e2-44e9-855f-861e7c08ae18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42c982e7-d4e2-44e9-855f-861e7c08ae18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_tree=ntc.parse(nltk_pos_tagged)\n",
        "print(chunk_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "jWNxl02OzNhq",
        "outputId": "6705b2b1-3766-4dfc-e1af-5eb3ef75bddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4c3b8fe506a0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchunk_tree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk_pos_tagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/nltk/chunk/api.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use accuracy(gold) instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftRHlKHb1fqO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}