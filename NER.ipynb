{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NLP Lab Practical 5\n",
        "Name: Aashi Khanna\n",
        "Roll No.: 02\n",
        "\n",
        "AIM-\n",
        "Named Entity Recognition and Dependency Parsing for Information Extration using spacy.\n",
        "Consider any text file (research article technical blog , any unstructured corpus used before)\n",
        "Perform NER to extract entities from individual sentences using spacy.\n",
        "use Dependency parsing, POS tagging to extract relationships between the entities.\n",
        "Create a tuple for information extraction\n",
        "T1( Entity1, Entity2, Relation label)\n",
        "Display no of such tuples extracted from considered corpus as extracted information"
      ],
      "metadata": {
        "id": "4KOp-ylkLvVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvtioHEmLZVD"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "MnOuqwlUL_Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load 'en_core_web_sm' model\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "numOfTuples = 0\n",
        "\n",
        "# Define a function to get the relation between two entities\n",
        "def get_relation(sent, ent1, ent2):\n",
        "  \"\"\"\n",
        "  Extract the relation between two entities in a sentence.\n",
        "  \"\"\"\n",
        "  relation = ''\n",
        "  for token in sent:\n",
        "    if token.text in (ent1, ent2):\n",
        "      if not relation:\n",
        "        relation = token.dep_\n",
        "      elif token.dep_ == 'conj':\n",
        "        relation = ' '.join([relation, token.dep_, token.head.text])\n",
        "  return relation\n",
        "\n",
        "\n",
        "# Read text from file\n",
        "with open('prac5NLP.txt', 'r') as f:\n",
        "  text = f.read()\n",
        "\n",
        "print(text + \"\\n\")\n",
        "\n",
        "# Create a spacy Doc object for the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over each sentence in the text\n",
        "for sent in doc.sents:\n",
        "\n",
        "  # Extract named entities from the sentence\n",
        "  entities = {} # Dictionary to hold the named entities in the sentence\n",
        "\n",
        "  for ent in sent.ents:\n",
        "    entities[ent.text] = ent.label_ # Add named entity to dictionary with its label as the value\n",
        "\n",
        "  # Extract relationships between the named entities in the sentence\n",
        "  relations = [] # List to hold the tuples of (Entity1, Entity2, Relation label)\n",
        "  for ent1 in entities:\n",
        "    for ent2 in entities:\n",
        "      if ent1 != ent2: # Don't compare entity to itself\n",
        "\n",
        "      # Get the relation between the entities\n",
        "        relation = get_relation(sent, ent1, ent2)\n",
        "        if relation:\n",
        "          relations.append((ent1, ent2, relation))\n",
        "          numOfTuples+=1\n",
        "\n",
        "  # Print the named entities and their relationships for the sentence\n",
        "  if entities:\n",
        "    print('Named entities:', entities)\n",
        "    if relations:\n",
        "      print('Relations:', relations)\n",
        "    else:\n",
        "      print('No relations found.')\n",
        "\n",
        "  print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T47dTzSGMG-O",
        "outputId": "ff543ba1-7b69-48c6-eb63-f1075e735193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spotify is available in most of Europe, as well as Africa, the Americas, Asia, and Oceania, with a total availability in 184 markets. \n",
            "\n",
            "Named entities: {'Spotify': 'ORG', 'Europe': 'LOC', 'Africa': 'LOC', 'Americas': 'LOC', 'Asia': 'LOC', 'Oceania': 'LOC', '184': 'CARDINAL'}\n",
            "Relations: [('Spotify', 'Europe', 'nsubj'), ('Spotify', 'Africa', 'nsubj'), ('Spotify', 'Americas', 'nsubj conj Africa'), ('Spotify', 'Asia', 'nsubj conj Americas'), ('Spotify', 'Oceania', 'nsubj conj Asia'), ('Spotify', '184', 'nsubj'), ('Europe', 'Spotify', 'nsubj'), ('Europe', 'Africa', 'pobj'), ('Europe', 'Americas', 'pobj conj Africa'), ('Europe', 'Asia', 'pobj conj Americas'), ('Europe', 'Oceania', 'pobj conj Asia'), ('Europe', '184', 'pobj'), ('Africa', 'Spotify', 'nsubj'), ('Africa', 'Europe', 'pobj'), ('Africa', 'Americas', 'pobj conj Africa'), ('Africa', 'Asia', 'pobj conj Americas'), ('Africa', 'Oceania', 'pobj conj Asia'), ('Africa', '184', 'pobj'), ('Americas', 'Spotify', 'nsubj conj Africa'), ('Americas', 'Europe', 'pobj conj Africa'), ('Americas', 'Africa', 'pobj conj Africa'), ('Americas', 'Asia', 'conj conj Americas'), ('Americas', 'Oceania', 'conj conj Asia'), ('Americas', '184', 'conj'), ('Asia', 'Spotify', 'nsubj conj Americas'), ('Asia', 'Europe', 'pobj conj Americas'), ('Asia', 'Africa', 'pobj conj Americas'), ('Asia', 'Americas', 'conj conj Americas'), ('Asia', 'Oceania', 'conj conj Asia'), ('Asia', '184', 'conj'), ('Oceania', 'Spotify', 'nsubj conj Asia'), ('Oceania', 'Europe', 'pobj conj Asia'), ('Oceania', 'Africa', 'pobj conj Asia'), ('Oceania', 'Americas', 'conj conj Asia'), ('Oceania', 'Asia', 'conj conj Asia'), ('Oceania', '184', 'conj'), ('184', 'Spotify', 'nsubj'), ('184', 'Europe', 'pobj'), ('184', 'Africa', 'pobj'), ('184', 'Americas', 'conj'), ('184', 'Asia', 'conj'), ('184', 'Oceania', 'conj')]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Number of such tuples: {numOfTuples}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mqx0dNrnNKMt",
        "outputId": "2ba92007-540a-4ce1-820a-24121b4301c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of such tuples: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.displacy.serve(doc, style=\"dep\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grZjC0lsPD3B",
        "outputId": "14ecd676-9ef3-43d2-8f26-53f9b71bb832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FVig0hKaPRbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}